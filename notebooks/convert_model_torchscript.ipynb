{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchmetrics\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MelSpectrogramNetwork(pl.LightningModule):\n",
    "    def __init__(self,in_channels,learning_rate,**kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels \n",
    "        self.learning_rate = learning_rate \n",
    "        self.cnn = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=self.in_channels,out_channels=8,kernel_size=(5,3)),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=5),\n",
    "          nn.Conv2d(in_channels=8,out_channels=64,kernel_size=(5,3)),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=5),\n",
    "          nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(5,3)),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=5)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential( \n",
    "          nn.Linear(in_features=(13312),out_features=1028),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(.5),\n",
    "          nn.Linear(in_features=(1028),out_features=256),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(.5),\n",
    "          nn.Linear(in_features=(256),out_features=2)\n",
    "        ) \n",
    "        # Here we are going to be adding our TorchMetrics \n",
    "        self.train_precision = torchmetrics.Precision(num_classes=2)\n",
    "        self.train_recall = torchmetrics.Recall(num_classes=2)\n",
    "        self.train_f1_score = torchmetrics.F1Score(num_classes=2)\n",
    "\n",
    "        self.val_precision = torchmetrics.Precision(num_classes=2)\n",
    "        self.val_recall = torchmetrics.Recall(num_classes=2)\n",
    "        self.val_f1_score = F=torchmetrics.F1Score(num_classes=2)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "    def shared_step(self,batch,stage):\n",
    "\n",
    "        mel_spec = batch[\"data\"].type(torch.cuda.FloatTensor)\n",
    "        y = batch[\"label\"]\n",
    "\n",
    "\n",
    "        assert mel_spec.ndim == 4 # (batch x C x H x W ) \n",
    "\n",
    "        y_hat = self.forward(mel_spec)\n",
    "        loss = F.cross_entropy(y_hat,y)\n",
    "        \n",
    "        return {f\"loss\":loss,\n",
    "        \"y_hat\":y_hat.detach(),\n",
    "        \"y\":y}\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        \n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        y = torch.cat([x['y'] for x in outputs])\n",
    "        \n",
    "        if stage == 'train':\n",
    "            self.train_precision(y_hat,y)\n",
    "            self.train_recall(y_hat,y)\n",
    "            self.train_f1_score(y_hat,y)\n",
    "\n",
    "            metrics = {\n",
    "            f\"{stage}_precision\":  self.train_precision,\n",
    "            f\"{stage}_recall\":  self.train_recall,\n",
    "            f\"{stage}_f1\": self.train_f1_score\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            self.val_precision(y_hat,y)\n",
    "            self.val_recall(y_hat,y)\n",
    "            self.val_f1_score(y_hat,y)\n",
    "            \n",
    "            metrics = {\n",
    "            f\"{stage}_precision\":  self.val_precision,\n",
    "            f\"{stage}_recall\":  self.val_recall,\n",
    "            f\"{stage}_f1\": self.val_f1_score\n",
    "            }\n",
    "        self.log_dict(metrics, prog_bar=True,on_step=False,on_epoch=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"train\")      \n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, \"train\")      \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"valid\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, \"valid\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"test\")  \n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate,weight_decay=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = MelSpectrogramNetwork.load_from_checkpoint(r'C:\\Users\\Tiam Moradi\\Documents\\Personal\\fb_capstone\\experiments\\epoch=35-step=1656.ckpt')\n",
    "script = model.to_torchscript()\n",
    "\n",
    "# save for use in production environment\n",
    "torch.jit.save(script, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fb_capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "754e8579695dab41ba444d594a96287f0224f8a50d9e264114f122805a4f108f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
